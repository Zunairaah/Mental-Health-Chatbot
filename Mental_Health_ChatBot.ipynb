{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing the required libraries**"
      ],
      "metadata": {
        "id": "lhQnBageMOnN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PcCkhRgMKvY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing and reading the corpus**"
      ],
      "metadata": {
        "id": "9EZmX4DxMtIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/Mental_Health_FAQ.csv'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "raw_doc = content.lower() #Converts text to lowercase\n",
        "nltk.download('punkt') #Using the Punkt tokenizer\n",
        "nltk.download('wordnet') #Using the WordNet dictionary\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc) #Converts doc to list of sentences\n",
        "word_tokens = nltk.word_tokenize(raw_doc) #Converts doc to list of words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK8T-rgfM6Xn",
        "outputId": "645a81a3-cfcf-4ba3-ccbb-342366875cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Example of Sentence tokens**"
      ],
      "metadata": {
        "id": "ZQBIt7GqQdfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK0wzGxRQfx4",
        "outputId": "f91d8d53-f23b-44ce-eae2-f496ad2c59fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['question_id,questions,answers\\n1590140,what does it mean to have a mental illness?,\"mental illnesses are health conditions that disrupt a personâ€™s thoughts, emotions, relationships, and daily functioning.',\n",
              " 'they are associated with distress and diminished capacity to engage in the ordinary activities of daily life.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Example of Word tokens**"
      ],
      "metadata": {
        "id": "TF-9cAm4Qxcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRd5mkutQ3B9",
        "outputId": "64d7e7ba-9e12-400a-fa7e-3e0ffa84436b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['question_id', ',', 'questions', ',', 'answers']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Preprocessing**"
      ],
      "metadata": {
        "id": "x5ML01LaRFhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "UGwISTlHRItD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining the Greeting Function**"
      ],
      "metadata": {
        "id": "jKPsNFcjSBzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GREET_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\",)\n",
        "GREET_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in GREET_INPUTS:\n",
        "      return random.choice(GREET_RESPONSES)"
      ],
      "metadata": {
        "id": "-t4gx8yASFGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Response Generation**"
      ],
      "metadata": {
        "id": "uXzHRJnBSP4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "82u1n47QSTZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response = ''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf == 0):\n",
        "    robo1_response = robo1_response + \"I am sorry! I don't understand you\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response + sent_tokens[idx]\n",
        "    return robo1_response"
      ],
      "metadata": {
        "id": "7ewkAJMmStkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining conversation start/end protocols**"
      ],
      "metadata": {
        "id": "ire1XqfBS9a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "print(\"BOT: My name is Zunaira. Let's have a conversation! Also, if you want to exit any time, just type Bye!\")\n",
        "while(flag == True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "  if(user_response != 'bye'):\n",
        "    if(user_response == 'thanks' or user_response == 'thank you'):\n",
        "      flag = False\n",
        "      print(\"BOT: You are welcome..\")\n",
        "    else:\n",
        "      if(greet(user_response) != None):\n",
        "        print(\"BOT: \" + greet(user_response))\n",
        "      else:\n",
        "        sent_tokens.append(user_response)\n",
        "        word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
        "        final_words = list(set(word_tokens))\n",
        "        print(\"BOT: \", end = \"\")\n",
        "        print(response(user_response))\n",
        "        sent_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag = False\n",
        "    print(\"BOT: Goodbye! Take care <3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iITPIuztTGqB",
        "outputId": "575a4e82-b6b8-4dc6-e55b-e1d5806cc759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: My name is Zunaira. Let's have a conversation! Also, if you want to exit any time, just type Bye!\n",
            "hi\n",
            "BOT: hi there\n",
            "i am zunaira\n",
            "BOT: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am sorry! I don't understand you\n",
            "ok no issue\n",
            "BOT: if you know someone who is having problems, don't assume that the issue will resolve itself.\n",
            "what do you mean by mental health\n",
            "BOT: 7995219,what's the difference between mental health and mental illness?,\"‘mental health’ and ‘mental illness’ are increasingly being used as if they mean the same thing, but they do not.\n",
            "do the drugs effect on mental health?\n",
            "BOT: and, while all drugs have an effect on the brain, the particular properties of the drug influence the level of risk of harmful consequences.\n",
            "give the basic information about mental health\n",
            "BOT: talk to your mental health.\n",
            "what is personality disorder?\n",
            "BOT: obsessive-compulsive personality disorder is one of the most common personality disorders.\n",
            "ok then bye bro\n",
            "BOT: I am sorry! I don't understand you\n",
            "i said bye\n",
            "BOT: people who experience did may have many unexplainable gaps in their memory, forget information they’re already learned, or have difficulties recalling things they’ve said or done.\n",
            "bye\n",
            "BOT: Goodbye! Take care <3\n"
          ]
        }
      ]
    }
  ]
}